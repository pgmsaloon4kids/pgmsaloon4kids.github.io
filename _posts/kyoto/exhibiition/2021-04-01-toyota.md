---
layout: exhibition
permalink: /kyoto/exhibition/toyota
title: 豊田陽介の展示ページ
author: toyota
icon: true
---
- 名前：豊田陽介（とよた ようすけ）
- 学年：40歳
- 住んでるところ：埼玉県
- プログラミング歴：27年

### やったことのあるプログラミング言語やツール

JavaScript、Scratch、MakeCode、UIFlow、C/C++、HTML/CSS、Java、Python、Swift、C#、PHP、BASIC

### 好きな（得意な）プログラミング言語やツール

JavaScript、ビジュアルプログラミング（Scratch、MakeCode、UIFlowなど）

### いつからプログラミングをやってますか？

初めてやってみたのは中学生の時で、きちんと習ったというのは大学生の時になります

## 作品紹介1

- 作品名：声や音色で小さなロボットカーtoioを動かそう！
- 言語（ツール）：プログラム：JavaScript、ロボットカー：toio

<div class="youtube">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/Ve6TyzzmXck" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

●音での制御やビジュアルプログラミングでの制御 #toio #toiotomo #MFTokyo2020 - YouTube
　[https://www.youtube.com/watch?v=Ve6TyzzmXck](https://www.youtube.com/watch?v=Ve6TyzzmXck)

### 作品の説明

ベルの音を鳴らしたり声でしゃべりかけたりすると、小さなロボットカーのtoioが動き出したり動き方が変わったりします

## これを作ろうと思った理由

メーカーフェアというイベントで、小さなロボットカーのtoioを使う展示をすることが決まったのが最初のきっかけです。そして詳しい内容を考える中で「小さい子でも分かりやすく楽しめるものを作れたら良いな」と思っていた時に、簡単に音などを使った機械学習が行える仕組み（Teachable Machine）を見つけて、楽器などと一緒に組み合わせたら楽しそうかも、と思ってこの作品ができあがりました。

### この作品はどのように進化しますか？もしくはこのあとどんな作品を作ろうと思っていますか？

「小さい子でもできる何かで、このロボットカーのtoioを操作できるものを作れたら良いな」と思っていて、この下の作品に出てくる「体の動きを使う」というものを組み合わせられたらと思っています。

## 作品紹介2

- 作品名：3Dバーチャル空間の中のモノを両手で操る！
- 言語（ツール）：JavaScript

<div class="youtube">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/ehJeN8pFHeI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

●p5.js ＋ MediaPipe Hands の組み合わせで WebGL による 3D表現を使ってみた - YouTube
　[https://www.youtube.com/watch?v=ehJeN8pFHeI](https://www.youtube.com/watch?v=ehJeN8pFHeI)

### 作品の説明

カメラにうつった自分の両手を画面の中で動かすことで、3Dの箱を操ることができます

### これを作ろうと思った理由

とても性能が良い両手を認識する仕組み（MediaPipe Hands）と、立体の箱など3Dのモノを表示させたりすることができたりする仕組み（p5.js ）の2つに、同じくらいの時期に興味がわいて、その2つを組み合わせたら面白いかもしれない、と思って作りました。

### この作品はどのように進化しますか？もしくはこのあとどんな作品を作ろうと思っていますか？

この両手を認識する仕組みで、魔方陣を出現させてみたり、アニメの敵キャラが使う呪文みたいなものを試せる仕組みを作ってみたりしたのですが、1つ目の作品のところで書いたように、モノと組み合わせた作品を作ってみたいです。

ちなみに、両手を認識する仕組みで試しに作った他の作品のリンクはこちらです。

●某アニメの悪役が使う「とっておきの手品」っぽいことができるアプリ - YouTube
　[https://www.youtube.com/watch?v=EkzZNFuWYNk](https://www.youtube.com/watch?v=EkzZNFuWYNk)

●MediaPipe Hands と p5.js の組み合わせで魔方陣を呼び出す仕組みを作ってみる - YouTube
　[https://www.youtube.com/watch?v=fCSlWxKvPJ4](https://www.youtube.com/watch?v=fCSlWxKvPJ4)

## 作品紹介3

- 作品名：画面の中のネコを手でつまんで動かす！
- 言語（ツール）：Stretch3  [https://stretch3.github.io/](https://stretch3.github.io/)

<div class="youtube">
  <iframe width="560" height="315" src="https://www.youtube.com/embed/qUS15suiDHc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

●Scratch Cat を指でつまんで動かしてみた 〜 Handpose2Scratch を利用〜 - YouTube
　[https://www.youtube.com/watch?v=qUS15suiDHc](https://www.youtube.com/watch?v=qUS15suiDHc)

### 作品の説明

画面の中にいるネコのキャラクターを、カメラにうつった自分の手でつまんで動かせます

### これを作ろうと思った理由

Scratch 3.0に機械学習・AIの仕組みを加えたりしている「Stretch3」というものがあって、その中にカメラにうつった手を認識する仕組み（Handpose2Scratch）がありました。それを見た時に「この仕組みを使って画面の中のキャラクターや物とやりとりができる何かが簡単に作れないかな？」と思って試したのがきっかけです。

### この作品はどのように進化しますか？もしくはこのあとどんな作品を作ろうと思っていますか？

この手を認識する仕組みを、ゲームのような作品など、別の楽しみ方ができる作品と組み合わせてみたいです。
